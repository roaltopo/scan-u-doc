{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25add83a-6a8a-4bc2-89bf-1886a909884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def eliminar_puntuacion(texto):\n",
    "    # Define una cadena de caracteres de puntuación\n",
    "    puntuacion = string.punctuation\n",
    "    \n",
    "    # Inicializa una cadena vacía para almacenar el texto sin puntuación\n",
    "    texto_sin_puntuacion = \"\"\n",
    "    \n",
    "    # Itera a través de cada carácter en el texto\n",
    "    for caracter in texto:\n",
    "        # Si el carácter no está en la cadena de puntuación, agrégalo al texto sin puntuación\n",
    "        if caracter not in puntuacion:\n",
    "            texto_sin_puntuacion += caracter\n",
    "    \n",
    "    return texto_sin_puntuacion.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d1b602-ff8d-46cb-a29e-5287dd54b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff9b718-6be2-4c4a-bb89-c27ed1cc284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# code changes ###############\n",
    "import intel_extension_for_pytorch as ipex\n",
    "############# code changes ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0854c35-d40c-454e-8f6c-e26a02286e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9715a9de46eb48c38f60bfb4e2f35bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3729893-fbe1-4440-9f0d-12e7d4fa6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "df_train = pd.read_pickle(\"data/train_df_new_wa.pkl\")\n",
    "df_test = pd.read_pickle(\"data/validation_df_new_wa.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb324643-f160-4fb6-845e-bbba1cd3a410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_ans_indices</th>\n",
       "      <th>review</th>\n",
       "      <th>human_ans_spans</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the result of Stan Wawrinka's match a...</td>\n",
       "      <td>(1207, 1222)</td>\n",
       "      <td>Lille, France (CNN) -- Roger Federer and Stan ...</td>\n",
       "      <td>6-1 3-6 6-3 6-2</td>\n",
       "      <td>6-1 3-6 6-3 6-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the nickname given to Fauja Singh by h...</td>\n",
       "      <td>(420, 436)</td>\n",
       "      <td>Hong Kong (CNN) -- Not your average great-grea...</td>\n",
       "      <td>turbaned tornado</td>\n",
       "      <td>turbaned tornado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was kidnapped?</td>\n",
       "      <td>(173, 185)</td>\n",
       "      <td>(CNN) -- Four months after a criminal investig...</td>\n",
       "      <td>Kyron Horman</td>\n",
       "      <td>Kyron Horman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are people upset with?</td>\n",
       "      <td>(36, 51)</td>\n",
       "      <td>(CNN) -- Los Angeles Clippers owner Donald Ste...</td>\n",
       "      <td>Donald Sterling</td>\n",
       "      <td>Donald Sterling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did she die?</td>\n",
       "      <td>(32, 64)</td>\n",
       "      <td>(CNN) -- The police officer who fatally shot a...</td>\n",
       "      <td>fatally shot a 93-year-old woman</td>\n",
       "      <td>she was fatally shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59057</th>\n",
       "      <td>Who was one part for?</td>\n",
       "      <td>(518, 538)</td>\n",
       "      <td>CHAPTER V. \\n\\n_THE WAR BETWEEN CÆSAR AND POMP...</td>\n",
       "      <td>one for the lawyers,</td>\n",
       "      <td>The lawyers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59058</th>\n",
       "      <td>did their father answer the door?</td>\n",
       "      <td>(468, 532)</td>\n",
       "      <td>CHAPTER XX. \\n\\nFOLLOWING ALLEN. \\n\\nHal was a...</td>\n",
       "      <td>The door was closed, and then Andy McCabe answ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59059</th>\n",
       "      <td>What is the political, cultural and economic c...</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>Bratislava ( or ; , or \"\" ) is the capital of ...</td>\n",
       "      <td>bratislava</td>\n",
       "      <td>bratislava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59060</th>\n",
       "      <td>How?</td>\n",
       "      <td>(1117, 1161)</td>\n",
       "      <td>(CNN) -- Obsession often brings joy and sorrow...</td>\n",
       "      <td>and then get some for my 31-year-old husband</td>\n",
       "      <td>she buys them for him in shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59061</th>\n",
       "      <td>Is anyone else trying to help?</td>\n",
       "      <td>(1552, 1574)</td>\n",
       "      <td>CHICAGO, Illinois (CNN) -- A man suspected of ...</td>\n",
       "      <td>Sens. Durbin and Obama</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59062 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question human_ans_indices  \\\n",
       "0      What was the result of Stan Wawrinka's match a...      (1207, 1222)   \n",
       "1      What is the nickname given to Fauja Singh by h...        (420, 436)   \n",
       "2                                     Who was kidnapped?        (173, 185)   \n",
       "3                             Who are people upset with?          (36, 51)   \n",
       "4                                       How did she die?          (32, 64)   \n",
       "...                                                  ...               ...   \n",
       "59057                              Who was one part for?        (518, 538)   \n",
       "59058                  did their father answer the door?        (468, 532)   \n",
       "59059  What is the political, cultural and economic c...           (0, 10)   \n",
       "59060                                               How?      (1117, 1161)   \n",
       "59061                     Is anyone else trying to help?      (1552, 1574)   \n",
       "\n",
       "                                                  review  \\\n",
       "0      Lille, France (CNN) -- Roger Federer and Stan ...   \n",
       "1      Hong Kong (CNN) -- Not your average great-grea...   \n",
       "2      (CNN) -- Four months after a criminal investig...   \n",
       "3      (CNN) -- Los Angeles Clippers owner Donald Ste...   \n",
       "4      (CNN) -- The police officer who fatally shot a...   \n",
       "...                                                  ...   \n",
       "59057  CHAPTER V. \\n\\n_THE WAR BETWEEN CÆSAR AND POMP...   \n",
       "59058  CHAPTER XX. \\n\\nFOLLOWING ALLEN. \\n\\nHal was a...   \n",
       "59059  Bratislava ( or ; , or \"\" ) is the capital of ...   \n",
       "59060  (CNN) -- Obsession often brings joy and sorrow...   \n",
       "59061  CHICAGO, Illinois (CNN) -- A man suspected of ...   \n",
       "\n",
       "                                         human_ans_spans  \\\n",
       "0                                        6-1 3-6 6-3 6-2   \n",
       "1                                       turbaned tornado   \n",
       "2                                           Kyron Horman   \n",
       "3                                        Donald Sterling   \n",
       "4                       fatally shot a 93-year-old woman   \n",
       "...                                                  ...   \n",
       "59057                               one for the lawyers,   \n",
       "59058  The door was closed, and then Andy McCabe answ...   \n",
       "59059                                         bratislava   \n",
       "59060       and then get some for my 31-year-old husband   \n",
       "59061                             Sens. Durbin and Obama   \n",
       "\n",
       "                               Answer  \n",
       "0                     6-1 3-6 6-3 6-2  \n",
       "1                    turbaned tornado  \n",
       "2                        Kyron Horman  \n",
       "3                     Donald Sterling  \n",
       "4                she was fatally shot  \n",
       "...                               ...  \n",
       "59057                    The lawyers.  \n",
       "59058                             yes  \n",
       "59059                      bratislava  \n",
       "59060  she buys them for him in shops  \n",
       "59061                             Yes  \n",
       "\n",
       "[59062 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a9904b-4183-40ac-8768-98b834bb6658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_question'] = df_train['Answer'].apply(lambda x: 1 if eliminar_puntuacion(x).lower() == 'yes' else (0 if eliminar_puntuacion(x).lower() == 'no' or eliminar_puntuacion(x).lower() == 'not' else None))\n",
    "df_train = df_train[['question', 'is_question', 'human_ans_spans']].rename(columns={'human_ans_spans': 'text', 'is_question': 'label'})\n",
    "df_train['question'] = df_train['question'] + '\\n'\n",
    "df_train['text'] = df_train['text'] + '\\n'\n",
    "df_train['answer0'] = 'no'\n",
    "df_train['answer1'] = 'yes'\n",
    "\n",
    "df_test['is_question'] = df_test['Answer'].apply(lambda x: 1 if eliminar_puntuacion(x).lower() == 'yes' else (0 if eliminar_puntuacion(x).lower() == 'no' or eliminar_puntuacion(x).lower() == 'not' else None))\n",
    "df_test = df_test[['question', 'is_question', 'human_ans_spans']].rename(columns={'human_ans_spans': 'text', 'is_question': 'label'})\n",
    "df_test['question'] = df_test['question'] + '\\n'\n",
    "df_test['text'] = df_test['text'] + '\\n'\n",
    "df_test['answer0'] = 'no'\n",
    "df_test['answer1'] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40298bb6-0d43-470d-be2e-aecd3fdc0ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>answer0</th>\n",
       "      <th>answer1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>did he cry a lot?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baby Will never cried\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>Did the riders leave late?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>were on their horses' backs at an early hour. \\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Did Walter lie about what happened?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Then Walter gave a truthful account \\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>do they use it in astronomy?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Myr is deprecated in geology, but in astronomy...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>Is it the largest city in Armenia?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>largest city of Armenia \\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10088</th>\n",
       "      <td>59044</td>\n",
       "      <td>Can singles get those distinctions as well?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>albums and singles\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10089</th>\n",
       "      <td>59046</td>\n",
       "      <td>Did they ever run out of money?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>filed for Chapter 11 bankruptcy\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10090</th>\n",
       "      <td>59051</td>\n",
       "      <td>Was he present when police showed up?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>only one of the parties involved was there\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091</th>\n",
       "      <td>59058</td>\n",
       "      <td>did their father answer the door?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The door was closed, and then Andy McCabe answ...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10092</th>\n",
       "      <td>59061</td>\n",
       "      <td>Is anyone else trying to help?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sens. Durbin and Obama\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10093 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                       question  label  \\\n",
       "0          7                            did he cry a lot?\\n    0.0   \n",
       "1         14                   Did the riders leave late?\\n    0.0   \n",
       "2         18          Did Walter lie about what happened?\\n    0.0   \n",
       "3         19                 do they use it in astronomy?\\n    1.0   \n",
       "4         21           Is it the largest city in Armenia?\\n    1.0   \n",
       "...      ...                                            ...    ...   \n",
       "10088  59044  Can singles get those distinctions as well?\\n    1.0   \n",
       "10089  59046              Did they ever run out of money?\\n    1.0   \n",
       "10090  59051        Was he present when police showed up?\\n    0.0   \n",
       "10091  59058            did their father answer the door?\\n    1.0   \n",
       "10092  59061               Is anyone else trying to help?\\n    1.0   \n",
       "\n",
       "                                                    text answer0 answer1  \n",
       "0                                Baby Will never cried\\n      no     yes  \n",
       "1       were on their horses' backs at an early hour. \\n      no     yes  \n",
       "2                 Then Walter gave a truthful account \\n      no     yes  \n",
       "3      Myr is deprecated in geology, but in astronomy...      no     yes  \n",
       "4                             largest city of Armenia \\n      no     yes  \n",
       "...                                                  ...     ...     ...  \n",
       "10088                               albums and singles\\n      no     yes  \n",
       "10089                  filed for Chapter 11 bankruptcy\\n      no     yes  \n",
       "10090       only one of the parties involved was there\\n      no     yes  \n",
       "10091  The door was closed, and then Andy McCabe answ...      no     yes  \n",
       "10092                           Sens. Durbin and Obama\\n      no     yes  \n",
       "\n",
       "[10093 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna(subset=['label'], inplace = True)\n",
    "df_train = df_train[['question', 'label', 'text', 'answer0', 'answer1']].reset_index()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "986f0452-4270-4bd5-a6e6-3c6a50455957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>answer0</th>\n",
       "      <th>answer1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Did he ever represent his country in Winter Ol...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Keung has never represented Switzerland at a W...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Is he a doctor?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dr. Kerns H. Powers, \\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Does he have any conditions?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bales has not entered a plea in the case, thou...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Do they know when to expect Joe?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Does she live in a house?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>They lived in an apartment.\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>6552</td>\n",
       "      <td>Was anyone in it?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the vacant building\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>6553</td>\n",
       "      <td>Is he ahead in the race?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>but the race is closer in Michigan, with the p...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>6557</td>\n",
       "      <td>were there 1000 people killed ?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>killing at least 14\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>6558</td>\n",
       "      <td>did she she apologize?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sarah said in a quiet voice, \"I'm sorry, Mom.\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>6562</td>\n",
       "      <td>was everything impossible?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anything seems possible\\n</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           question  label  \\\n",
       "0         2  Did he ever represent his country in Winter Ol...    0.0   \n",
       "1         3                                  Is he a doctor?\\n    1.0   \n",
       "2        10                     Does he have any conditions?\\n    1.0   \n",
       "3        15                 Do they know when to expect Joe?\\n    0.0   \n",
       "4        29                        Does she live in a house?\\n    0.0   \n",
       "...     ...                                                ...    ...   \n",
       "1109   6552                                Was anyone in it?\\n    0.0   \n",
       "1110   6553                         Is he ahead in the race?\\n    0.0   \n",
       "1111   6557                  were there 1000 people killed ?\\n    0.0   \n",
       "1112   6558                           did she she apologize?\\n    1.0   \n",
       "1113   6562                       was everything impossible?\\n    0.0   \n",
       "\n",
       "                                                   text answer0 answer1  \n",
       "0     Keung has never represented Switzerland at a W...      no     yes  \n",
       "1                               Dr. Kerns H. Powers, \\n      no     yes  \n",
       "2     Bales has not entered a plea in the case, thou...      no     yes  \n",
       "3                                                  no\\n      no     yes  \n",
       "4                         They lived in an apartment.\\n      no     yes  \n",
       "...                                                 ...     ...     ...  \n",
       "1109                              the vacant building\\n      no     yes  \n",
       "1110  but the race is closer in Michigan, with the p...      no     yes  \n",
       "1111                              killing at least 14\\n      no     yes  \n",
       "1112    Sarah said in a quiet voice, \"I'm sorry, Mom.\\n      no     yes  \n",
       "1113                          Anything seems possible\\n      no     yes  \n",
       "\n",
       "[1114 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dropna(subset=['label'], inplace = True)\n",
    "df_test = df_test[['question', 'label', 'text', 'answer0', 'answer1']].reset_index()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f7f9f6-896b-4cbd-a41b-e2874b63c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['index', 'question', 'label', 'text', 'answer0', 'answer1'],\n",
       "        num_rows: 10093\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'question', 'label', 'text', 'answer0', 'answer1'],\n",
       "        num_rows: 1114\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': Dataset.from_pandas(df_train),\n",
    "    'test': Dataset.from_pandas(df_test)\n",
    "})\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44160279-a119-478f-b0b3-7b3f1b945d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f0ca00-e1f6-4af6-b632-0b511320368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"answer0\", \"answer1\"]\n",
    "n = len(ending_names)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * n for context in examples[\"text\"]]\n",
    "    question_headers = examples[\"question\"]\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    return {k: [v[i : i + n] for i in range(0, len(v), n)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e85d378c-348a-446c-8d58-fb49e3744d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a81bb03da74ed1b1d70d84586a2edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10093 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aaca50e63a47818c474862cd740300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6754679-afdc-4e73-a227-418ba9bdc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d60cb641-90ba-4210-b25c-bc8bb1cc875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ac2288-d0bd-40ad-8e30-cfdc12040a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a69fc-b490-480f-a022-e9d4099ce3bb",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88d94971-4022-4e67-b51c-652eb8cd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb86d7ad-c763-48de-9662-90a4466a5c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:484: UserWarning: Split Master Weight feature is not supported on XPU for now, disabled.\n",
      "  warnings.warn(\"Split Master Weight feature is not supported on XPU for now, disabled.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:500: UserWarning: Weight Prepack and Sample Input are both disabled on XPU. The Onednn Layout is automatically applied.\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1893' max='1893' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1893/1893 1:04:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.340122</td>\n",
       "      <td>0.855476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.462415</td>\n",
       "      <td>0.844704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.769005</td>\n",
       "      <td>0.851885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:494: UserWarning: To reduce device memory usage on XPU, optimization are done inplace, setting the inplace argument to True.\n",
      "  warnings.warn(\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:527: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:484: UserWarning: Split Master Weight feature is not supported on XPU for now, disabled.\n",
      "  warnings.warn(\"Split Master Weight feature is not supported on XPU for now, disabled.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:494: UserWarning: To reduce device memory usage on XPU, optimization are done inplace, setting the inplace argument to True.\n",
      "  warnings.warn(\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:500: UserWarning: Weight Prepack and Sample Input are both disabled on XPU. The Onednn Layout is automatically applied.\n",
      "  warnings.warn(\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:527: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:484: UserWarning: Split Master Weight feature is not supported on XPU for now, disabled.\n",
      "  warnings.warn(\"Split Master Weight feature is not supported on XPU for now, disabled.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:494: UserWarning: To reduce device memory usage on XPU, optimization are done inplace, setting the inplace argument to True.\n",
      "  warnings.warn(\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:500: UserWarning: Weight Prepack and Sample Input are both disabled on XPU. The Onednn Layout is automatically applied.\n",
      "  warnings.warn(\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:527: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1893, training_loss=0.24637082337199603, metrics={'train_runtime': 3871.8313, 'train_samples_per_second': 7.82, 'train_steps_per_second': 0.489, 'total_flos': 3133643033364696.0, 'train_loss': 0.24637082337199603, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"yn_answer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    use_ipex=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee9da24-00c2-47d2-8ac9-5127d5ef9fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/roaltopo/yn_answer/tree/main/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b5601-074a-492a-9e35-44e1d8a144c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
